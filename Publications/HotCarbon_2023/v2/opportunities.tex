\section{Opportunities}
\label{opportunities}
%- We need traceability end to end \\
A fundamental requirement would be to establish a reliable system to collect, store and report data concerning the power/energy utilization across the complete lifecycle of the AI model. Such a challenge poses significant difficulties as certain facilities may lack the capacity for monitoring or measuring. Furthermore, even in facilities equipped with monitoring capabilities, the methodologies employed for measuring power/energy could vary widely, such as how to allocate shared resources for model training. Consequently, this issue can be bifurcated into two principal aspects: standardization and reliable information tracking.

First and foremost, it is important to standardize the procedures employed for measuring, collecting, and reporting {power/energy/} carbon consumption data pertaining to the AI model. This measure would enable consistent and comparable reporting metrics. This paper takes a step towards that goal, more work is needed on the system energy consumption, in particular in lieu of sharing. Additionally, it is important to ensure accuracy and integrity of the records. 
Models and data sets should be published with a data sheet that reports based on the metrics. 
%The achievement of this objective would necessitate extensive consultations with various stakeholders, including AI engineers, data center facility managers and operators, and experts in Green House Gas Protocol.
%
%Secondly, it is crucial to ensure the accuracy and integrity of the recorded performance and energy consumption data during the quantification process. This issue can be addressed through the implementation of either a centralized or distributed system. 
%In this context, blockchain-based solutions are particularly well-suited to our requirements, given their distributed nature and the immutability of the data they contain.
%- per use case optimization (in context) \\
Yet another area is use case based optimization. The first advantage of the proposed approach is mind-set shifts in the AI model design process. Historically, AI models have been developed with an emphasis on performance. However, upon considering our AI lifetime observability matrics, system designers would begin to prioritize both performance and energy efficiency in their AI model architectures, as evidenced by factors such as neural network depth, width, input resolution, and parameters~\cite{DESISLAVOV2023100857}. This would facilitate the development of AI models that are not only high-performing but also energy-efficient, thereby reducing the need for unnecessary training practices. In particular, it would be necessary to develop methods to compare different life cycle strategies in the context of use cases, i.e., re-use (and what) vs. start from scratch. 

Furthermore, this approach would allow for the identification of inefficiencies within the various phases of AI, which could be targeted for optimization. Through the implementation of scheduling techniques and power knob configurations (such as power capping and dynamic voltage and frequency scaling), we would be able to enhance the utilization of each resource while simultaneously reducing energy consumption. 
%This would be achieved through a comprehensive understanding of the underlying energy-performance trade-offs that exist in different phases of the AI model lifecycle.